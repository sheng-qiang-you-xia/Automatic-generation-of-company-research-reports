"""
æ·±å…¥è´¢åŠ¡ç ”æŠ¥åˆ†æä¸ç”Ÿæˆè„šæœ¬ï¼ˆç®€æ´ç‰ˆï¼‰
åŸºäºè‡ªåŠ¨åŒ–é‡‡é›†ä¸åˆ†æçš„è´¢åŠ¡ç ”æŠ¥æ±‡æ€»ï¼Œç»“åˆå¤§æ¨¡å‹èƒ½åŠ›ï¼Œç”Ÿæˆè¯¦ç»†çš„å…¬å¸è´¢åŠ¡ã€è‚¡æƒã€è¡Œä¸šã€ä¼°å€¼ã€æ²»ç†ç»“æ„ç­‰å¤šç»´åº¦æ·±åº¦åˆ†æä¸æŠ•èµ„å»ºè®®ã€‚
"""

import os
import yaml
from datetime import datetime
from data_analysis_agent.config.llm_config import LLMConfig
from data_analysis_agent.utils.llm_helper import LLMHelper
import re
import shutil
import requests
from urllib.parse import urlparse

def load_report_content(md_path):
    with open(md_path, "r", encoding="utf-8") as f:
        return f.read()

def get_background():
    return '''
æœ¬æŠ¥å‘ŠåŸºäºè‡ªåŠ¨åŒ–é‡‡é›†ä¸åˆ†ææµç¨‹ï¼Œæ¶µç›–å¦‚ä¸‹ç¯èŠ‚ï¼š
- å…¬å¸åŸºç¡€ä¿¡æ¯ç­‰æ•°æ®å‡é€šè¿‡akshareã€å…¬å¼€å¹´æŠ¥ã€ä¸»æµè´¢ç»æ•°æ®æºè‡ªåŠ¨é‡‡é›†ã€‚
- è´¢åŠ¡ä¸‰å¤§æŠ¥è¡¨æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œ-æ¸¯è‚¡-è´¢åŠ¡æŠ¥è¡¨-ä¸‰å¤§æŠ¥è¡¨ (https://emweb.securities.eastmoney.com/PC_HKF10/FinancialAnalysis/index)
- ä¸»è¥ä¸šåŠ¡ä¿¡æ¯æ¥æºï¼šåŒèŠ±é¡º-ä¸»è¥ä»‹ç» (https://basic.10jqka.com.cn/new/000066/operate.html)
- è‚¡ä¸œç»“æ„ä¿¡æ¯æ¥æºï¼šåŒèŠ±é¡º-è‚¡ä¸œä¿¡æ¯ (https://basic.10jqka.com.cn/HK0020/holder.html) é€šè¿‡ç½‘é¡µçˆ¬è™«æŠ€æœ¯è‡ªåŠ¨é‡‡é›†
- è¡Œä¸šä¿¡æ¯é€šè¿‡DuckDuckGoç­‰å…¬å¼€æœç´¢å¼•æ“è‡ªåŠ¨æŠ“å–ï¼Œå¼•ç”¨äº†æƒå¨æ–°é—»ã€ç ”æŠ¥ã€å…¬å¸å…¬å‘Šç­‰ã€‚
- è´¢åŠ¡åˆ†æã€å¯¹æ¯”åˆ†æã€ä¼°å€¼ä¸é¢„æµ‹å‡ç”±å¤§æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰è‡ªåŠ¨ç”Ÿæˆï¼Œç»“åˆäº†è¡Œä¸šå¯¹æ ‡ã€è´¢åŠ¡æ¯”ç‡ã€æ²»ç†ç»“æ„ç­‰å¤šç»´åº¦å†…å®¹ã€‚
- ç›¸å…³æ•°æ®ä¸åˆ†æå‡åœ¨è„šæœ¬è‡ªåŠ¨åŒ–æµç¨‹ä¸‹å®Œæˆï¼Œç¡®ä¿æ•°æ®æ¥æºå¯è¿½æº¯ã€åˆ†æé€»è¾‘é€æ˜ã€‚
- è¯¦ç»†å¼•ç”¨ä¸å¤–éƒ¨é“¾æ¥å·²åœ¨æ­£æ–‡ä¸­æ ‡æ³¨ã€‚
- æ•°æ®æ¥å£è¯´æ˜ä¸å…è´£å£°æ˜è§æ–‡æœ«ã€‚
'''

def get_llm():
    api_key = os.environ.get("OPENAI_API_KEY")
    base_url = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
    model = os.environ.get("OPENAI_MODEL", "gpt-4")
    llm_config = LLMConfig(api_key=api_key, base_url=base_url, model=model)
    return LLMHelper(llm_config)

def generate_outline(llm, background, report_content):
    outline_prompt = f"""
ä½ æ˜¯ä¸€ä½é¡¶çº§é‡‘èåˆ†æå¸ˆå’Œç ”æŠ¥æ’°å†™ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹èƒŒæ™¯å’Œè´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è¯¦å°½çš„ã€Šå•†æ±¤ç§‘æŠ€å…¬å¸ç ”æŠ¥ã€‹åˆ†æ®µå¤§çº²ï¼Œè¦æ±‚ï¼š
- ä»¥yamlæ ¼å¼è¾“å‡ºï¼ŒåŠ¡å¿…ç”¨```yamlå’Œ```åŒ…è£¹æ•´ä¸ªyamlå†…å®¹ï¼Œä¾¿äºåç»­è‡ªåŠ¨åˆ†å‰²ã€‚
- æ¯ä¸€é¡¹ä¸ºä¸€ä¸ªä¸»è¦éƒ¨åˆ†ï¼Œæ¯éƒ¨åˆ†éœ€åŒ…å«ï¼š
  - part_title: ç« èŠ‚æ ‡é¢˜
  - part_desc: æœ¬éƒ¨åˆ†å†…å®¹ç®€ä»‹
- ç« èŠ‚éœ€è¦†ç›–å…¬å¸åŸºæœ¬é¢ã€è´¢åŠ¡åˆ†æã€è¡Œä¸šå¯¹æ¯”ã€ä¼°å€¼ä¸é¢„æµ‹ã€æ²»ç†ç»“æ„ã€æŠ•èµ„å»ºè®®ã€é£é™©æç¤ºã€æ•°æ®æ¥æºç­‰ã€‚
- åªè¾“å‡ºyamlæ ¼å¼çš„åˆ†æ®µå¤§çº²ï¼Œä¸è¦è¾“å‡ºæ­£æ–‡å†…å®¹ã€‚

ã€èƒŒæ™¯è¯´æ˜å¼€å§‹ã€‘
{background}
ã€èƒŒæ™¯è¯´æ˜ç»“æŸã€‘

ã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹å¼€å§‹ã€‘
{report_content}
ã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹ç»“æŸã€‘
"""
    outline_list = llm.call(
        outline_prompt,
        system_prompt="ä½ æ˜¯ä¸€ä½é¡¶çº§é‡‘èåˆ†æå¸ˆå’Œç ”æŠ¥æ’°å†™ä¸“å®¶ï¼Œå–„äºç»“æ„åŒ–ã€åˆ†æ®µè§„åˆ’è¾“å‡ºï¼Œåˆ†æ®µå¤§çº²å¿…é¡»ç”¨```yamlåŒ…è£¹ï¼Œä¾¿äºåç»­è‡ªåŠ¨åˆ†å‰²ã€‚",
        max_tokens=4096,
        temperature=0.3
    )
    print("\n===== ç”Ÿæˆçš„åˆ†æ®µå¤§çº²å¦‚ä¸‹ =====\n")
    print(outline_list)
    try:
        if '```yaml' in outline_list:
            yaml_block = outline_list.split('```yaml')[1].split('```')[0]
        else:
            yaml_block = outline_list
        parts = yaml.safe_load(yaml_block)
        if isinstance(parts, dict):
            parts = list(parts.values())
    except Exception as e:
        print(f"[å¤§çº²yamlè§£æå¤±è´¥] {e}")
        parts = []
    return parts

def generate_section(llm, part_title, prev_content, background, report_content, is_last):
    section_prompt = f"""
ä½ æ˜¯ä¸€ä½é¡¶çº§é‡‘èåˆ†æå¸ˆå’Œç ”æŠ¥æ’°å†™ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹å†…å®¹ï¼Œç›´æ¥è¾“å‡º\"{part_title}\"è¿™ä¸€éƒ¨åˆ†çš„å®Œæ•´ç ”æŠ¥å†…å®¹ã€‚

**é‡è¦è¦æ±‚ï¼š**
1. ç›´æ¥è¾“å‡ºå®Œæ•´å¯ç”¨çš„ç ”æŠ¥å†…å®¹ï¼Œä»¥\"## {part_title}\"å¼€å¤´
2. åœ¨æ­£æ–‡ä¸­å¼•ç”¨æ•°æ®ã€äº‹å®ã€å›¾ç‰‡ç­‰ä¿¡æ¯æ—¶ï¼Œé€‚å½“ä½ç½®æ’å…¥å‚è€ƒèµ„æ–™ç¬¦å·ï¼ˆå¦‚[1][2][3]ï¼‰ï¼Œç¬¦å·éœ€ä¸æ–‡æœ«å¼•ç”¨æ–‡çŒ®ç¼–å·ä¸€è‡´
3. **å›¾ç‰‡å¼•ç”¨è¦æ±‚ï¼ˆåŠ¡å¿…ä¸¥æ ¼éµå®ˆï¼‰ï¼š**
   - åªå…è®¸å¼•ç”¨ã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹ã€‘ä¸­çœŸå®å­˜åœ¨çš„å›¾ç‰‡åœ°å€ï¼ˆæ ¼å¼å¦‚ï¼š./images/å›¾ç‰‡åå­—.pngï¼‰ï¼Œå¿…é¡»ä¸åŸæ–‡å®Œå…¨ä¸€è‡´ã€‚
   - ç¦æ­¢è™šæ„ã€æœæ’°ã€æ”¹ç¼–ã€çŒœæµ‹å›¾ç‰‡åœ°å€ï¼Œæœªåœ¨ã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹ã€‘ä¸­å‡ºç°çš„å›¾ç‰‡ä¸€å¾‹ä¸å¾—å¼•ç”¨ã€‚
   - å¦‚éœ€æ’å…¥å›¾ç‰‡ï¼Œå¿…é¡»å…ˆåœ¨ã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹ã€‘ä¸­æŸ¥æ‰¾ï¼Œæœªæ‰¾åˆ°åˆ™ä¸æ’å…¥å›¾ç‰‡ï¼Œç»ä¸ç¼–é€ å›¾ç‰‡ã€‚
   - å¦‚å¼•ç”¨äº†ä¸å­˜åœ¨çš„å›¾ç‰‡ï¼Œå°†è¢«åˆ¤ä¸ºé”™è¯¯è¾“å‡ºã€‚
4. ä¸è¦è¾“å‡ºä»»ä½•ã€xxxå¼€å§‹ã€‘ã€xxxç»“æŸã€‘ç­‰åˆ†éš”ç¬¦
5. ä¸è¦è¾“å‡º\"å»ºè®®è¡¥å……\"ã€\"éœ€è¦æ·»åŠ \"ç­‰æç¤ºæ€§è¯­è¨€
6. ä¸è¦ç¼–é€ å›¾ç‰‡åœ°å€æˆ–æ•°æ®
7. å†…å®¹è¦è¯¦å®ã€ä¸“ä¸šï¼Œå¯ç›´æ¥ä½¿ç”¨

**æ•°æ®æ¥æºæ ‡æ³¨ï¼š**
- è´¢åŠ¡æ•°æ®æ ‡æ³¨ï¼šï¼ˆæ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œ-æ¸¯è‚¡-è´¢åŠ¡æŠ¥è¡¨[1]ï¼‰
- ä¸»è¥ä¸šåŠ¡ä¿¡æ¯æ ‡æ³¨ï¼šï¼ˆæ•°æ®æ¥æºï¼šåŒèŠ±é¡º-ä¸»è¥ä»‹ç»[2]ï¼‰
- è‚¡ä¸œç»“æ„ä¿¡æ¯æ ‡æ³¨ï¼šï¼ˆæ•°æ®æ¥æºï¼šåŒèŠ±é¡º-è‚¡ä¸œä¿¡æ¯ç½‘é¡µçˆ¬è™«[3]ï¼‰

ã€æœ¬æ¬¡ä»»åŠ¡ã€‘
{part_title}

ã€å·²ç”Ÿæˆå‰æ–‡ã€‘
{prev_content}

ã€èƒŒæ™¯è¯´æ˜å¼€å§‹ã€‘
{background}
ã€èƒŒæ™¯è¯´æ˜ç»“æŸã€‘

ã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹å¼€å§‹ã€‘
{report_content}
ã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹ç»“æŸã€‘
"""
    if is_last:
        section_prompt += """
è¯·åœ¨æœ¬èŠ‚æœ€åä»¥"å¼•ç”¨æ–‡çŒ®"æ ¼å¼ï¼Œåˆ—å‡ºæ‰€æœ‰æ­£æ–‡ä¸­ç”¨åˆ°çš„å‚è€ƒèµ„æ–™ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[1] ä¸œæ–¹è´¢å¯Œ-æ¸¯è‚¡-è´¢åŠ¡æŠ¥è¡¨: https://emweb.securities.eastmoney.com/PC_HKF10/FinancialAnalysis/index
[2] åŒèŠ±é¡º-ä¸»è¥ä»‹ç»: https://basic.10jqka.com.cn/new/000066/operate.html
[3] åŒèŠ±é¡º-è‚¡ä¸œä¿¡æ¯: https://basic.10jqka.com.cn/HK0020/holder.html
"""
    section_text = llm.call(
        section_prompt,
        system_prompt="ä½ æ˜¯é¡¶çº§é‡‘èåˆ†æå¸ˆï¼Œä¸“é—¨ç”Ÿæˆå®Œæ•´å¯ç”¨çš„ç ”æŠ¥å†…å®¹ã€‚è¾“å‡ºå¿…é¡»æ˜¯å®Œæ•´çš„ç ”æŠ¥æ­£æ–‡ï¼Œæ— éœ€ç”¨æˆ·ä¿®æ”¹ã€‚ä¸¥æ ¼ç¦æ­¢è¾“å‡ºåˆ†éš”ç¬¦ã€å»ºè®®æ€§è¯­è¨€æˆ–è™šæ„å†…å®¹ã€‚åªå…è®¸å¼•ç”¨çœŸå®å­˜åœ¨äºã€è´¢åŠ¡ç ”æŠ¥æ±‡æ€»å†…å®¹ã€‘ä¸­çš„å›¾ç‰‡åœ°å€ï¼Œä¸¥ç¦è™šæ„ã€çŒœæµ‹ã€æ”¹ç¼–å›¾ç‰‡è·¯å¾„ã€‚å¦‚å¼•ç”¨äº†ä¸å­˜åœ¨çš„å›¾ç‰‡ï¼Œå°†è¢«åˆ¤ä¸ºé”™è¯¯è¾“å‡ºã€‚",
        max_tokens=8192,
        temperature=0.5
    )
    return section_text

def save_markdown(content, output_file):
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"\nğŸ“ æ·±åº¦è´¢åŠ¡ç ”æŠ¥åˆ†æå·²ä¿å­˜åˆ°: {output_file}")

def format_markdown(output_file):
    try:
        import subprocess
        format_cmd = ["mdformat", output_file]
        subprocess.run(format_cmd, check=True, capture_output=True, text=True, encoding='utf-8')
        print(f"âœ… å·²ç”¨ mdformat æ ¼å¼åŒ– Markdown æ–‡ä»¶: {output_file}")
    except Exception as e:
        print(f"[æç¤º] mdformat æ ¼å¼åŒ–å¤±è´¥: {e}\nè¯·ç¡®ä¿å·²å®‰è£… mdformat (pip install mdformat)")

def convert_to_docx(output_file, docx_output="Company_Research_Report.docx"):
    try:
        import subprocess
        import shutil
        import os
        
        # æ£€æŸ¥pandocæ˜¯å¦å¯ç”¨
        if shutil.which("pandoc") is None:
            print("â„¹ï¸  pandoc æœªå®‰è£…ï¼Œè·³è¿‡Wordæ–‡æ¡£ç”Ÿæˆ")
            print("   å¦‚éœ€ç”ŸæˆWordæ–‡æ¡£ï¼Œè¯·å®‰è£…pandoc: https://pandoc.org/installing.html")
            return
            
        pandoc_cmd = [
            "pandoc",
            output_file,
            "-o",
            docx_output,
            "--standalone",
            "--resource-path=.",
            "--extract-media=."
        ]
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        
        result = subprocess.run(pandoc_cmd, capture_output=True, text=True, encoding='utf-8', env=env)
        
        if result.returncode == 0:
            print(f"\nğŸ“„ Wordç‰ˆæŠ¥å‘Šå·²ç”Ÿæˆ: {docx_output}")
        else:
            print(f"âš ï¸  pandocè½¬æ¢å¤±è´¥: {result.stderr}")
            print("   å»ºè®®æ£€æŸ¥å›¾ç‰‡è·¯å¾„æ˜¯å¦æ­£ç¡®")
            
    except FileNotFoundError:
        print("â„¹ï¸  pandoc æœªå®‰è£…ï¼Œè·³è¿‡Wordæ–‡æ¡£ç”Ÿæˆ")
        print("   å¦‚éœ€ç”ŸæˆWordæ–‡æ¡£ï¼Œè¯·å®‰è£…pandoc: https://pandoc.org/installing.html")
    except Exception as e:
        print(f"âš ï¸  pandocè½¬æ¢æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# å›¾ç‰‡è·¯å¾„é¢„å¤„ç†ï¼šå°† md æ–‡ä»¶ä¸­çš„å›¾ç‰‡å…¨éƒ¨æœ¬åœ°åŒ–åˆ° images ç›®å½•ï¼Œå¹¶æ›¿æ¢ä¸º ./images/xxx.png è·¯å¾„
def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def is_url(path):
    return path.startswith('http://') or path.startswith('https://')

def download_image(url, save_path):
    try:
        resp = requests.get(url, stream=True, timeout=10)
        resp.raise_for_status()
        with open(save_path, 'wb') as f:
            for chunk in resp.iter_content(1024):
                f.write(chunk)
        return True
    except Exception as e:
        print(f"[ä¸‹è½½å¤±è´¥] {url}: {e}")
        return False

def copy_image(src, dst):
    try:
        shutil.copy2(src, dst)
        return True
    except Exception as e:
        print(f"[å¤åˆ¶å¤±è´¥] {src}: {e}")
        return False

def extract_images_from_markdown(md_path, images_dir, new_md_path):
    ensure_dir(images_dir)
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # åŒ¹é… ![alt](path) å½¢å¼çš„å›¾ç‰‡
    pattern = re.compile(r'!\[[^\]]*\]\(([^)]+)\)')
    matches = pattern.findall(content)
    used_names = set()
    replace_map = {}
    not_exist_set = set()

    for img_path in matches:
        img_path = img_path.strip()
        # å–æ–‡ä»¶å
        if is_url(img_path):
            filename = os.path.basename(urlparse(img_path).path)
        else:
            filename = os.path.basename(img_path)
        # é˜²æ­¢é‡å
        base, ext = os.path.splitext(filename)
        i = 1
        new_filename = filename
        while new_filename in used_names:
            new_filename = f"{base}_{i}{ext}"
            i += 1
        used_names.add(new_filename)
        new_img_path = os.path.join(images_dir, new_filename)
        # ä¸‹è½½æˆ–å¤åˆ¶
        img_exists = True
        if is_url(img_path):
            success = download_image(img_path, new_img_path)
            if not success:
                img_exists = False
        else:
            # æ”¯æŒç»å¯¹å’Œç›¸å¯¹è·¯å¾„
            abs_img_path = img_path
            if not os.path.isabs(img_path):
                abs_img_path = os.path.join(os.path.dirname(md_path), img_path)
            if not os.path.exists(abs_img_path):
                print(f"[è­¦å‘Š] æœ¬åœ°å›¾ç‰‡ä¸å­˜åœ¨: {abs_img_path}")
                img_exists = False
            else:
                copy_image(abs_img_path, new_img_path)
        # è®°å½•æ›¿æ¢
        if img_exists:
            replace_map[img_path] = f'./images/{new_filename}'
        else:
            not_exist_set.add(img_path)

    # æ›¿æ¢ markdown å†…å®¹ï¼Œä¸å­˜åœ¨çš„å›¾ç‰‡ç›´æ¥åˆ é™¤æ•´ä¸ªå›¾ç‰‡è¯­æ³•
    def replace_func(match):
        orig = match.group(1).strip()
        if orig in not_exist_set:
            return ''  # åˆ é™¤ä¸å­˜åœ¨çš„å›¾ç‰‡è¯­æ³•
        return match.group(0).replace(orig, replace_map.get(orig, orig))

    new_content = pattern.sub(replace_func, content)
    with open(new_md_path, 'w', encoding='utf-8') as f:
        f.write(new_content)
    print(f"å›¾ç‰‡å¤„ç†å®Œæˆï¼æ–°æ–‡ä»¶: {new_md_path}")

def main():
    # ====== å›¾ç‰‡è·¯å¾„é¢„å¤„ç†ï¼Œè‡ªåŠ¨ç”Ÿæˆæœ¬åœ° images è·¯å¾„çš„ markdown æ–‡ä»¶ ======
    raw_md_path = "è´¢åŠ¡ç ”æŠ¥æ±‡æ€»_20250709_154438.md"  # åŸå§‹è¾“å…¥ markdown
    new_md_path = "è´¢åŠ¡ç ”æŠ¥æ±‡æ€»_20250709_154438_images.md"  # å¤„ç†åè¾“å‡º markdown
    images_dir = os.path.join(os.path.dirname(raw_md_path), 'images')
    extract_images_from_markdown(raw_md_path, images_dir, new_md_path)

    # åç»­æµç¨‹ç”¨ new_md_path
    report_content = load_report_content(new_md_path)
    background = get_background()
    llm = get_llm()
    parts = generate_outline(llm, background, report_content)
    full_report = ['# å•†æ±¤ç§‘æŠ€å…¬å¸ç ”æŠ¥\n']
    prev_content = ''
    for idx, part in enumerate(parts):
        part_title = part.get('part_title', f'éƒ¨åˆ†{idx+1}')
        print(f"\n===== æ­£åœ¨ç”Ÿæˆï¼š{part_title} =====\n")
        is_last = (idx == len(parts) - 1)
        section_text = generate_section(
            llm, part_title, prev_content, background, report_content, is_last
        )
        full_report.append(section_text)
        print(f"\n===== å·²ç”Ÿæˆï¼š{part_title}ï¼ˆé¢„è§ˆå‰2000å­—ç¬¦ï¼‰ =====\n")
        print(section_text[:2000])
        print("\n===== æœ¬éƒ¨åˆ†å†…å®¹ç»“æŸ =====\n")
        prev_content = '\n'.join(full_report)
    final_report = '\n\n'.join(full_report)
    output_file = f"æ·±åº¦è´¢åŠ¡ç ”æŠ¥åˆ†æ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    save_markdown(final_report, output_file)
    format_markdown(output_file)
    convert_to_docx(output_file)
    
    # æ€»ç»“ä¿¡æ¯
    print("\n" + "="*60)
    print("ğŸ‰ æ·±åº¦è´¢åŠ¡ç ”æŠ¥ç”Ÿæˆå®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“„ ä¸»è¦è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“ å›¾ç‰‡ç›®å½•: {images_dir}")
    print(f"ğŸ“ å¤„ç†åçš„è¾“å…¥æ–‡ä»¶: {new_md_path}")
    print("\nğŸ’¡ å¯é€‰å·¥å…·å®‰è£…å»ºè®®:")
    print("   â€¢ æ ¼å¼åŒ–Markdown: pip install mdformat")
    print("   â€¢ ç”ŸæˆWordæ–‡æ¡£: å®‰è£…pandoc (https://pandoc.org/installing.html)")
    print("="*60)

if __name__ == "__main__":
    main()